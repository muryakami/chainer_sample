Script started on Wed Jan 13 23:12:13 2016
[1m[7m%[27m[1m[0m                                                                                                                                                                                  [0m[27m[24m[J[32m[yuki@hostname][00m ~/survey/workspace/2016
% [Kccat SdA_mnist_y.py
##############################################################################
import argparse

import numpy as np
import six

import chainer
from chainer import cuda
import chainer.functions as F
from chainer import optimizers

from sklearn.datasets import fetch_mldata
import matplotlib.pyplot as plt
import time
import math
import pickle

#from libdnn import StackedAutoEncoder

##############################################################################

workspace = '/Users/yuki/survey/workspace/'
fig_home = '{}pic_test5/'.format(workspace)

##############################################################################

parser = argparse.ArgumentParser(description='Chainer example: MNIST')
parser.add_argument('--gpu', '-g', default=-1, type=int,
                    help='GPU ID (negative value indicates CPU)')
parser.add_argument('model') ###
 # GPUãŒä½¿ãˆã‚‹ã‹ç¢ºèª
args = parser.parse_args()
if args.gpu >= 0:
    cuda.check_cuda_available()
xp = cuda.cupy if args.gpu >= 0 else np

##############################################################################

# ç¢ºçŽ‡çš„å‹¾é…é™ä¸‹æ³•ã§å­¦ç¿’ã•ã›ã‚‹éš›ã®ï¼‘å›žåˆ†ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
batchsize = 100
# å­¦ç¿’ã®ç¹°ã‚Šè¿”ã—å›žæ•°
n_epoch   = 30
# ä¸­é–“å±¤ã®æ•°
#n_units   = (28**2, 16**2, 8**2, 10)
n_units   = (28**2, 14**2, 7**2)
# ãƒŽã‚¤ã‚ºä»˜åŠ æœ‰ç„¡
#noised = False

##############################################################################
"""
# MNISTã®æ‰‹æ›¸ãæ•°å­—ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
print('fetch MNIST dataset')
mnist = fetch_mldata('MNIST original', data_home='~/survey')
print('Complete!')


# mnist.data : 70,000ä»¶ã®784æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿
mnist.data   = mnist.data.astype(np.float32)
mnist.data  /= 255     # 0-1ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
# mnist.target : æ­£è§£ãƒ‡ãƒ¼ã‚¿ï¼ˆæ•™å¸«ãƒ‡ãƒ¼ã‚¿ï¼‰
mnist.target = mnist.target.astype(np.int32)


# å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ Nå€‹ã€æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æ®‹ã‚Šã®å€‹æ•°ã¨è¨­å®š
N = 60000
y_train, y_test = np.split(mnist.data.copy(), [N])
#N_test = y_test.shape[0]
N_test = y_test.size

#if noised:
#    # Add noise
#    noise_ratio = 0.2
#    for data in mnist.data:
#        perm = np.random.permutation(mnist.data.shape[1])[:int(mnist.data.shape[1]*noise_ratio)]
#        data[perm] = 0.0

x_train, x_test = np.split(mnist.data, [N])
"""

###
print('fetch MNIST dataset')
mnist = fetch_mldata('MNIST original', data_home='~/survey/')
print('Complete!')
perm = np.random.permutation(len(mnist.data))
mnist.data = mnist.data.astype(np.float32) / 255
train_data = mnist.data[perm][:60000]
test_data = mnist.data[perm][60000:]
###

##############################################################################

depth = 2 ###
order = (('enc1', 'enc2'), ('dec2', 'dec1')) ###

#model = chainer.FunctionSet(
#    enc1=F.Linear(n_units[0], n_units[1]),
#    enc2=F.Linear(n_units[1], n_units[2]),
#    dec2=F.Linear(n_units[2], n_units[1]),
#    dec1=F.Linear(n_units[1], n_units[0])
#)
if args.model == '': ###
    model = chainer.FunctionSet(
        enc1=F.Linear(n_units[0], n_units[1]),
        enc2=F.Linear(n_units[1], n_units[2]),
        dec2=F.Linear(n_units[2], n_units[1]),
        dec1=F.Linear(n_units[1], n_units[0])
    )
else: ###
    model = pickle.load(open(args.model, 'rb')) ###

##############################################################################

# GPUä½¿ç”¨ã®æ™‚ã¯GPUã«ãƒ¢ãƒ‡ãƒ«ã‚’è»¢é€
if args.gpu >= 0:
    cuda.get_device(args.gpu).use()
    model.to_gpu()

##############################################################################

sublayer = []

loss_function = F.mean_squared_error
loss_param = {}

##############################################################################

def set_order(encl, decl):
    if len(encl) != len(decl):
        raise TypeError('Encode/Decode layers mismatch')

    #depth = len(encl)

    for (el, dl) in zip(encl, reversed(decl)):
        submodel = chainer.FunctionSet(
            enc=model[el],
            dec=model[dl]
        )
        sublayer.append(submodel)


set_order(*order)

##############################################################################

optimizer = optimizers.AdaDelta()
optimizer.setup(model)

##############################################################################

def __encode(x, layer, train):
    if train:
        x = F.dropout(x, ratio=0.2, train=train)
    if layer == 0:
        return x
    x = F.sigmoid(model.enc1(x))
    if layer == 1:
        return x
    x = F.sigmoid(model.enc2(x))
    if layer == 2:
        return x
    return x

##############################################################################

def __decode(x, layer=None, train=False):
    if not train or layer == 2:
        x = F.sigmoid(model.dec2(x))
    if not train or layer == 1:
        x = F.sigmoid(model.dec1(x))
    return x

##############################################################################

def encode(x_data, layer=None, train=False):
    if args.gpu >= 0:
        x_data = chainer.cuda.to_gpu(x_data)

    x = chainer.Variable(x_data)

    return __encode(x, layer, train)

##############################################################################

def validate(x_data, layer=None, train=False):
    targ = encode(x_data, layer-1, train=False)
    code = encode(x_data, layer, train=train)
    
    y = __decode(code, layer, train=train)
    
    return loss_function(targ, y, **loss_param)


def train(x_data, batchsize=100, action=(lambda: None)):
        errs = []
        N = len(x_data)
        perm = np.random.permutation(N)

        for l in range(1, depth+1):
            optimizer.setup(sublayer[l-1])

            sum_error = 0.

            for i in range(0, N, batchsize):
                x_batch = x_data[perm[i:i+batchsize]]
                #x_batch = xp.asarray(x_data[perm[i:i+batchsize]])

                optimizer.zero_grads()
                err = validate(x_batch, layer=l, train=True)

                err.backward()
                optimizer.update()

                sum_error += float(chainer.cuda.to_cpu(err.data)) * len(x_batch)
                #sum_error += float(err.data) * len(x_batch)
                action()

            errs.append(sum_error / N)

        return tuple(errs)

##############################################################################

def forward(x_data, train=False):
    code = encode(x_data, train=train)
    y = __decode(code, train=train)
    
    return y


def test(x_data, batchsize=100, action=(lambda: None)):
        N = len(x_data)
        perm = np.random.permutation(N)

        sum_error = 0.

        for i in range(0, N, batchsize):
            x_batch = x_data[perm[i:i+batchsize]]
            #x_batch = xp.asarray(x_data[perm[i:i+batchsize]])
            y = forward(x_batch, train=False)

            if args.gpu >= 0:
                x_batch = chainer.cuda.to_gpu(x_batch)
            x = chainer.Variable(x_batch)

            err = loss_function(x, y, **loss_param)

            sum_error += float(chainer.cuda.to_cpu(err.data)) * len(x_batch)
            action()

        return sum_error / N

##############################################################################

# save trained network parameters to file
def save_param(dst='./network.param.npy'):
    # model.to_cpu() seems to change itself
    # This causes step-by-step saving each epochs with gpu
    param = np.array(model.to_cpu().parameters)
    np.save(dst, param)
    if args.gpu >= 0:
        model.to_gpu()

# load pre-trained network parameters from file
def load_param(src='./network.param.npy'):
    if not os.path.exists(src):
        raise IOError('specified parameter file does not exists')

    param = np.load(src)
    model.copy_parameters_from(param)

    # by this process, model parameters to be cpu_array
    if args.gpu >= 0:
        model = model.to_gpu()

##############################################################################

# draw digit images
def draw_layer(data, index, length):
    column = math.sqrt(length)
    row = math.sqrt(length)
    #column = 15
    #row = math.ceil(length/column)
    size = math.sqrt(data.shape[0])
    plt.subplot(row, column, index+1)  # è¡Œæ•°, åˆ—æ•°, ãƒ—ãƒ­ãƒƒãƒˆç•ªå·
    Z = data.reshape(size, size)       # convert from vector to 28x28 matrix
    Z = Z[::-1, :]                     # flip vertical
    plt.xlim(0, size)
    plt.ylim(0, size)
    plt.pcolor(Z)
    plt.title('%d'%index, size=8)
    plt.gray()
    plt.tick_params(labelbottom='off')
    plt.tick_params(labelleft='off')

##############################################################################

def image_save(data, str):
    #save_home = './pic_test4/{}.png'.format(str)
    save_home = '{}{}.png'.format(fig_home, str)
    print('plot start : {}.png'.format(str))
    
    plt.style.use('fivethirtyeight')
    size = math.sqrt(data.shape[0])
    plt.figure(figsize=(size, size*1.045))
    
    print('data.shape :', data.shape)
    print('data.shape[0] :', data.shape[0])

    for i in six.moves.range(data.shape[0]):
        draw_layer(data[i], i, data.shape[0])
        
    plt.savefig(save_home, bbox_inches='tight', pad_inches=0.0)
    plt.close() #
    print('plot end : {}.png'.format(str))
    print()

##############################################################################

# Neural net architecture
# é€”ä¸­ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æµã™ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®æ§‹é€ 
def dec_forward(x_data, layer):
    x = chainer.Variable(x_data.astype(np.float32))
    if layer >= 2:
        x = F.sigmoid(model.dec2(x))
    y = model.dec1(x)
    return y

def enc_forward(x_data, layer):
    x = chainer.Variable(x_data.astype(np.float32))
    y = model.enc1(x)
    if layer <= 1:
        return y
    y = model.enc2(F.sigmoid(y))
    return y

##############################################################################

#period = 1000
period = 10
for epoch in six.moves.range(1, int(n_epoch/period)+1):

    for i in six.moves.range(period):
        print('epoch : %d' %((epoch-1)*period +(i+1)))

        err = train(train_data, batchsize=200)
        print(err)

        perm = np.random.permutation(len(test_data))
        terr = test(test_data[perm][:100])
        print(terr)

        with open('{}sda.log'.format(fig_home), mode='a') as f:
            f.write("%d %f %f %f\n" % ((epoch-1)*period +(i+1), err[0], err[1], terr))

        save_param('{}sda.param.npy'.format(fig_home))

    # å¯è¦–åŒ–ãƒ¡ã‚½ãƒƒãƒ‰
    ew1 = np.array(model.enc1.W)
    image_save(ew1, 'ew1({})_images'.format(epoch * period))
    ew2 = np.array(model.enc2.W)
    image_save(ew2, 'ew2({})_images'.format(epoch * period))
    dw2_T = np.array(model.dec2.W).T
    image_save(dw2_T, 'dw2_T({})_images'.format(epoch * period))
    dw1_T = np.array(model.dec1.W).T
    image_save(dw1_T, 'dw1_T({})_images'.format(epoch * period))
    #......
    for i in six.moves.range(1, depth+1):
        # identity: å˜ä½è¡Œåˆ—ã®ç”Ÿæˆ(æ­£æ–¹è¡Œåˆ—), eye: identityã¨ä¼¼ã¦ã„ã‚‹ãŒåˆ—æ•°æŒ‡å®šå‡ºæ¥ã‚‹
        dec_hidden_x = np.identity(n_units[i])
        dec_hidden_y = dec_forward(dec_hidden_x, i)
        
        # hidden layerã‚’å¯è¦–åŒ–
        dec_hidden = np.array(dec_hidden_y.data)
        image_save(dec_hidden, 'dec_hL{}({})_images'.format(i, epoch * period))
        
        # identity: å˜ä½è¡Œåˆ—ã®ç”Ÿæˆ(æ­£æ–¹è¡Œåˆ—), eye: identityã¨ä¼¼ã¦ã„ã‚‹ãŒåˆ—æ•°æŒ‡å®šå‡ºæ¥ã‚‹
        enc_hidden_x = np.identity(n_units[0])
        enc_hidden_y = enc_forward(enc_hidden_x, i)
        
        # hidden layerã‚’å¯è¦–åŒ–
        enc_hidden_T = np.array(enc_hidden_y.data).T
        image_save(enc_hidden_T, 'enc_hL{}({})_T_images'.format(i, epoch * period))

    # æ¶ˆæ»…ã™ã‚‹å‹¾é…å•é¡Œæ¤œè¨¼
    test_ew1 = chainer.Variable(ew1)
    test_dw1_T = chainer.Variable(dw1_T)
    print('Layer1 :', F.mean_squared_error(test_ew1, test_dw1_T).data)
    test_ew2 = chainer.Variable(ew2)
    test_dw2_T = chainer.Variable(dw2_T)
    print('Layer2 :', F.mean_squared_error(test_ew2, test_dw2_T).data)


model.to_cpu()
pickle.dump(model, open('{}test_SAE.pkl'.format(fig_home), 'wb'), -1)

##############################################################################
[1m[7m%[27m[1m[0m                                                                                                                                                                                  [0m[27m[24m[J[32m[yuki@hostname][00m ~/survey/workspace/2016
% [Keexit

Script done on Wed Jan 13 23:12:27 2016
